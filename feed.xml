<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://libinliang866.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://libinliang866.github.io/" rel="alternate" type="text/html" hreflang="en" /><updated>2022-08-13T14:30:46+00:00</updated><id>https://libinliang866.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
</subtitle><entry><title type="html">Presentation of the department seminar about the high-dimensional interpolation</title><link href="https://libinliang866.github.io/blog/2022/presentation1/" rel="alternate" type="text/html" title="Presentation of the department seminar about the high-dimensional interpolation" /><published>2022-04-13T17:39:00+00:00</published><updated>2022-04-13T17:39:00+00:00</updated><id>https://libinliang866.github.io/blog/2022/presentation1</id><content type="html" xml:base="https://libinliang866.github.io/blog/2022/presentation1/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Discussion about benign overfitting]]></summary></entry><entry><title type="html">Tangent Kernel of Deep Neural Network</title><link href="https://libinliang866.github.io/blog/2022/NTK/" rel="alternate" type="text/html" title="Tangent Kernel of Deep Neural Network" /><published>2022-02-26T16:40:16+00:00</published><updated>2022-02-26T16:40:16+00:00</updated><id>https://libinliang866.github.io/blog/2022/NTK</id><content type="html" xml:base="https://libinliang866.github.io/blog/2022/NTK/"><![CDATA[<p>Given the neural network with the struture as below:</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ntk_1-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/ntk_1-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/ntk_1-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/ntk_1.png" />

  </picture>

</figure>

<p>If we consider the inner product of the gradient for different input \(x\) and \(x^\prime\), given the width of the neural network is infiite, the inner product will be deterministic kernel dependending on the depth \(L\) and the non-linearity activation.</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ntk_2-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/ntk_2-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/ntk_2-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/ntk_2.png" />

  </picture>

</figure>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ntk_3-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/ntk_3-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/ntk_3-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/ntk_3.png" />

  </picture>

</figure>

<p>With the gradient, we can write down the linearization of the neural network.</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ntk_4-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/ntk_4-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/ntk_4-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/ntk_4.png" />

  </picture>

</figure>

<p>And then we can derive the expression of the linearization of the neural network during training.</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ntk_5-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/ntk_5-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/ntk_5-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/ntk_5.png" />

  </picture>

</figure>

<p>Given new testing point \(x\in X_T\), we can derive the distribution of the output of the trained linearization neural network as below</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/ntk_6-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/ntk_6-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/ntk_6-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/ntk_6.png" />

  </picture>

</figure>

<p>Results from paper Wide Neural Networks of Any Depth Evolve asLinear Models Under Gradient Descent claim that with the width of the neural network large enough, the neural network will be close to the linearization counterparts.</p>]]></content><author><name></name></author><category term="deep" /><category term="learning" /><category term="NTK" /><summary type="html"><![CDATA[Deep Neural Network Tangent Kernel]]></summary></entry><entry><title type="html">Deep neural network with infinite width</title><link href="https://libinliang866.github.io/blog/2021/dnngp/" rel="alternate" type="text/html" title="Deep neural network with infinite width" /><published>2021-12-03T21:01:00+00:00</published><updated>2021-12-03T21:01:00+00:00</updated><id>https://libinliang866.github.io/blog/2021/dnngp</id><content type="html" xml:base="https://libinliang866.github.io/blog/2021/dnngp/"><![CDATA[<p>To study the infinite width of neural network is of interest because of two main reasons. The first one is that the neural networks applied in the real application usually have a large width so they may share similar properties as neural networks with inifinite width. The other reason is that the neural networks with inifinite width usually have explicit properties that is easy to study. Here we try to introduce the result about the initial distribution of deep neural network with inifinite width from Jaehoon Lee etc. In this result, the initial output of the deep neural network with inifinite width will become a Gaussian Process with a kernel having a compositional structure.</p>

<h2 id="structure-of-deep-neural-network">Structure of Deep Neural Network</h2>

<p>Given input \(x\in \mathbb{R}^d\), the deep neural network with \(L\) hidden layers can be expressed as the following.</p>

\[z_i^l(x)=b_i^l+\sum_{j=1}^{N_l}W_{ij}^lx_{j}^l(x),~~~~~ x_j^l(x)=\phi(z_j^{l-1}(x))~~~~~~~ l=1,...,L\]

<p>where \(\phi(\cdot)\) is the non-linear activation such as \(tanh\) or $ReLU$.</p>

<h2 id="deep-neural-network-with-infinite-width">Deep Neural Network with Infinite width</h2>

<p>We can first derive the distribution of the output for one layer and then extend to multiple layers.</p>

\[\newline\newline\]

<h3 id="single-layer-case">Single Layer Case</h3>

<p>Now we consider the deep neural network with only 1-layer. Given the bias \(b_i^0\sim_{i.i.d}N(0,\sigma_b^2)\) and weight \(W_{ij}^0 \sim_{i.i.d} N(0,\frac{\sigma_w^2}{d})\), then we could have</p>

\[z_i^0(x)\sim_{i.i.d} N(0, \sigma_b^2+\sigma_w^2 \frac{||x||^2}{d})~~~~ i=1,...,N_1\]

<p>And we have \(x_i^1 = \phi(z_i^0(x))\) are i.i.d.(Independent and identical distributed). Given \(b^1 \sim N(0,\sigma_b^2)\) and \(W_{i}^1\sim N(0,\frac{\sigma_w^2}{N_1})\)</p>

<p>Then with central limit theorem, we have</p>

\[lim_{N_1\rightarrow \infty}  z^1(x) = b^1 + W_{i}^1 x_i^1(x) \sim N(0, \sigma_b^2 + \sigma_w^2 K^0(x,x))\]

<p>Where \(K^0(x,x^\prime)=E_{z_1^0(x)}[\phi(z_1^0(x))\phi(z_1^0(x^\prime))]\).</p>

<p>For the covariance between \(z^1(x)\) and \(z^1(x^\prime)\). we have</p>

\[lim_{N_1\rightarrow \infty} cov(z^1(x), z^1(x^\prime)) = \sigma_b^2 + \sigma_w^2 K^1(x,x) = K^1(x,x^\prime)\]

<p>That is, with single layer case, the initial output \(\{z^1(x)\}\) will have be a Gaussian process with kernel \(K^1(\cdot,\cdot)\).</p>

\[\newline\newline\]

<h3 id="multiple-layers-case">Multiple Layers Case</h3>

<p>For \(L&gt;1\), given the initialization of bias \(b_i^l\sim N(0,\sigma_b^2) ~~ i=0,...,L\) and weights \(W_{ij}^l\sim N(0,\frac{\sigma_w^2}{N^{l}}) ~~ i=0,...,L\),we can define the compositional kernel. That is,</p>

\[K^0(x,x^\prime)=\frac{&lt;x,x^\prime&gt;}{d} 
\newline
K^l(x,x^\prime)=\sigma_b^2 + \sigma_w^2 K^{l-1}(x,x^\prime)  ~~~~ l=1,...,L\]

<p>It can be proved that the for the deep neural network with \(L\) hidden layer and with the initialization illustrated as above, we could have the initial output \(\{z^L(x)\}\) will be a Gaussian process with kernel \(K^L(\cdot, \cdot)\).</p>

\[\newline\newline\]

<h3 id="bayesian-inference-with-deep-neural-network-kernel">Bayesian Inference with Deep Neural Network Kernel</h3>

<p>Let the dataset be \(D=\lbrace x^i,t^i\rbrace_{i=1,...,n}\). Further assume that \(t^i \vert z^L(x^i)\sim N(0,\sigma_\epsilon^2)\). Then given a new data point \(x^*\), we have</p>

\[z^* \vert D, x \sim N(\bar{\mu}, \bar{\sigma}^2)\]

\[\bar{\mu} = K_{x^\*, D}(K_{D,D}+\sigma_\epsilon^2 I_n)^{-1}t\]

\[\bar{\sigma}^2 = K_{x^\*,x^\*} - K_{x^\*, D}(K_{D,D}+\sigma_\epsilon^2 I_n)^{-1}K_{x^\*, D}^T\]

<p>So that we can make a prediction with Bayesian Inference.</p>

<h2 id="numerical-study">Numerical Study</h2>

<p>The numerical study will based on doing the bayesian inference with deep neural network kernel on the data set MNIST and CIFAR10.</p>

<h3 id="compare-with-the-neural-network-with-finite-width">Compare with the Neural Network with finite width</h3>

<p>Then we have the results as below:</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/dnngp_numerical_experiment-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/dnngp_numerical_experiment-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/dnngp_numerical_experiment-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/dnngp_numerical_experiment.png" />

  </picture>

</figure>

<p>We can observe that the results of bayesian inference with deep neural network kernel often outperforms the neural network with finite width. Moreover, the wider the neural network, the results will be closer to the bayesian inference with deep neural network kernel.</p>]]></content><author><name></name></author><category term="Deep" /><category term="learning" /><category term="DNNGP" /><summary type="html"><![CDATA[Deep neural network with infinite width]]></summary></entry><entry><title type="html">Presentation of Machine learning class</title><link href="https://libinliang866.github.io/blog/2021/presentation3/" rel="alternate" type="text/html" title="Presentation of Machine learning class" /><published>2021-11-23T17:39:00+00:00</published><updated>2021-11-23T17:39:00+00:00</updated><id>https://libinliang866.github.io/blog/2021/presentation3</id><content type="html" xml:base="https://libinliang866.github.io/blog/2021/presentation3/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction about automatic captioning with Attention model]]></summary></entry><entry><title type="html">What bs() and ns() really do?</title><link href="https://libinliang866.github.io/blog/2021/bspline/" rel="alternate" type="text/html" title="What bs() and ns() really do?" /><published>2021-09-10T21:01:00+00:00</published><updated>2021-09-10T21:01:00+00:00</updated><id>https://libinliang866.github.io/blog/2021/bspline</id><content type="html" xml:base="https://libinliang866.github.io/blog/2021/bspline/"><![CDATA[<p>It is well known that we ususally apply the bs() and ns() to get the basis of smoothing spline. 
But do we really know how the function generate the basis? This note will introduce how the bs() and ns() function in R generate the basis design.</p>

<p>The process of bs() is as below:</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_1-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_1-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_1-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_1.png" />

  </picture>

</figure>

<p>And we also offer the code to replicate the result of bs().</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_2-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_2-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_2-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_2.png" />

  </picture>

</figure>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_3-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_3-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_3-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_3.png" />

  </picture>

</figure>

<p>We can compare our reuslts and those generated by bs() as below.</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_4-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_4-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_4-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_4.png" />

  </picture>

</figure>

<p>For the ns(), we have the process as below:</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_5-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_5-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_5-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_5.png" />

  </picture>

</figure>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_6-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_6-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_6-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_6.png" />

  </picture>

</figure>

<p>And then we write our own R code to realize the ns() and we compare the results generated by ns() as below:</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/bs_7-480.webp" />
    <source media="(max-width: 800px)" srcset="/assets/img/bs_7-800.webp" />
    <source media="(max-width: 1400px)" srcset="/assets/img/bs_7-1400.webp" />
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/bs_7.png" />

  </picture>

</figure>]]></content><author><name></name></author><category term="Nonparameteric" /><category term="statistics" /><category term="spline" /><summary type="html"><![CDATA[Describe what function bs() and ns() in R really do]]></summary></entry><entry><title type="html">Presentation of the department seminar about the Low Rank Anova Model</title><link href="https://libinliang866.github.io/blog/2021/presentation2/" rel="alternate" type="text/html" title="Presentation of the department seminar about the Low Rank Anova Model" /><published>2021-04-09T17:39:00+00:00</published><updated>2021-04-09T17:39:00+00:00</updated><id>https://libinliang866.github.io/blog/2021/presentation2</id><content type="html" xml:base="https://libinliang866.github.io/blog/2021/presentation2/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[Discussion about the Low Rank Anova Model]]></summary></entry></feed>